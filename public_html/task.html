<!DOCTYPE html>

<html lang="en">
    <head>
        <link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" rel="stylesheet"/>
        <link href="css/style.css" rel="stylesheet"/>
        <script src="https://unpkg.com/scrollreveal@4"></script>
        <link href='https://fonts.googleapis.com/css?family=Oswald:400,700' rel='stylesheet' type='text/css'>
        <link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
        <link href='https://fonts.googleapis.com/css?family=Avenir' type='text/css'>
        <link href='https://fonts.googleapis.com/css?family=Ubuntu' type='text/css'>
        <link href='https://fonts.googleapis.com/css?family=Roboto' type='text/css'>
    </head>
    <body>
        <nav class="navbar navbar-expand-md navbar-light bg-light" id = "myHeader">
            <a class="navbar-brand" href="/"><span class="red">Scavenger Hunt</span></span></a>
            <div class="collapse navbar-collapse" id="navbar">
                <ul class="navbar-nav ml-auto mt-2">
                    <li class="nav-item"><a class="nav-link" href="/register">About</a></li>
                    <li class="nav-item"><a class="nav-link" href="/register">Register</a></li>
                    <li class="nav-item"><a class="nav-link" href="/login">Log In</a></li>
                </ul>
            </div>
        </nav>

        <section id="main" class = "full">
			<header class="major">
				<h2>Color Shirt</h2>
			</header>
			<section id="content">
				<p> In this task, the robot needs to take a picture of a person who wears a shirt in a specific color. <br /> <br /> The color can be red, blue, green or yellow, and is provided as part of this task. Since the process of interpreting a color, say blue, can be very subjective, we will accept a color to be blue, if most people would identify the color as blue rather than another solid color such as, red, green or yellow. <br /> <br /> The format of "color shirt" is jpg, that saying the completion certificate of this task is an image in jpg format. The score of an in-time, correct completion is 100. This task is mainly used for demonstrating the vision module of intelligent robots. It makes sense for robots to actively search areas with more human activities, so robots with a good navigation capability can perform better in this task. </p>
            </section>

            <header class="major">
				<h2>Target Search</h2>
			</header>
            <section id="content">
				<p> This task requires a robot to visually localize a target object in a 3D environment. <br /> <br /> We maintain a list of objects that are easily accessible anywhere around the world, such as a can of coke. An instance of this task is specified by giving the name of a target object (from this list) in plain text. Therefore, each team needs to maintain a mapping from the name of any object on the list to an set of visual representations. A representation can be an image or a point cloud (in case of robot using RGB-D sensors). <br /> <br /> The format this this task is jpg. This task is mainly used for evaluating the vision and navigation capabilities, as robots need to simultaneously move its platform from point to point and visually analyzing scenes being visited. </p>
            </section>

            <header class="major">
				<h2>Human Following</h2>
			</header>
            <section id="content">
				<p> This task requires a robot to follow a human walker for at least a predefined distance. <br /> <br /> The completion certificate of this task includes a picture of the human walker and an image showing the trajectories traveled by the human walker and the robot. </p>
            </section>

            <header class="major">
				<h2>Object Delivery</h2>
			</header>
            <section id="content">
				<p> The format of completion certificate is txt. The score of an in-time, correct completion is 150. This task is used for demonstrating human-robot interactions, navigation and vision. The robot needs to find a person P1 who is willing to help specify the object name O, initial room R1, and goal room R2. To avoid language ambiguities, object names and room numbers can be selected through drop-down menus, or the robot can suggest humans to follow well-specified script (e.g., "Please input the room number. You can type 'r101', 'r102', 'r103', or 'r200'"). In so doing, the robot may want to actively seek human input in busy areas. After that, the robot needs to move to R1 to load object O (possibly with human P2's help). Finally, the robot moves object O to room R2 and asks the last human P3 to describe the object with a few words. The completion certificate includes the time-stamped object name given by P1 and the time-stamped words P3 used for describing the object. </p>
            </section>
		</section>

        <footer id="footer" class = "foot">
        	<span class="copyright">
        		&copy; Copyright 2018 University of Texas at Austin Learning Agents Research Lab. All rights reserved.</a>
        	</span>
        </footer>
    </body>
<html>
